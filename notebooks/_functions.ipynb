{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25708e3c-c565-42c1-9809-e164ad51c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install matplotlib (usually comes with Anaconda/Jupyter, but good to ensure)\n",
    "!pip install matplotlib --quiet\n",
    "\n",
    "# Install numpy (usually comes with Anaconda/Jupyter, but good to ensure)\n",
    "!pip install numpy --quiet\n",
    "\n",
    "# Install igraph\n",
    "!pip install igraph --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c5d776-eee9-4b87-923f-74dfa44785fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors \n",
    "import numpy as np\n",
    "import os \n",
    "import igraph as ig\n",
    "import time\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111e125c-00a6-4f69-ad64-a29a05028ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_from_gml_file(graph_file: str, weight_attribute_name: str = \"weight\"):\n",
    "    # Check if the graph file exists\n",
    "    if not os.path.exists(graph_file):\n",
    "        print(f\"Error: Graph file '{graph_file}' not found.\")\n",
    "        print(f\"Please ensure '{graph_file}' is a valid path to your 'lesmis.gml' file.\")\n",
    "        print(\"You can typically find this file by searching for 'lesmis.gml network dataset'.\")\n",
    "        return # Exit the function if file is not found\n",
    "\n",
    "    try:\n",
    "        # Load network from GML file\n",
    "        # igraph.Graph.Read_GML will automatically load edge attributes like 'value'\n",
    "        # if they are present in the GML file.\n",
    "        graph = ig.Graph.Read_GML(graph_file)\n",
    "        \n",
    "        # Check if the graph has the correct weight attribute name\n",
    "        if weight_attribute_name not in graph.edge_attributes():\n",
    "            print(f\"Warning: Graph '{graph_file}' does not have a '{weight_attribute_name}' attribute. \"\n",
    "                  \"Community detection will proceed without explicit weights, or if the algorithm \"\n",
    "                  \"expects them, it might use default uniform weights.\")\n",
    "            # If no 'value' attribute, assign a default uniform weight for visualization purposes\n",
    "            graph.es[weight_attribute_name] = 1 \n",
    "\n",
    "        return graph\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading or processing the graph: {e}\")\n",
    "        return\n",
    "\n",
    "def community_detection(graph: ig.Graph, community_detection_method: str = \"multilevel\", weight_attribute_name: str = \"weight\"):\n",
    "    if community_detection_method == \"multilevel\":\n",
    "        return graph.community_multilevel(weights=weight_attribute_name if weight_attribute_name in graph.edge_attributes() else None)\n",
    "    elif community_detection_method == \"fastgreedy\":\n",
    "        return graph.community_fastgreedy(weights=weight_attribute_name if weight_attribute_name in graph.edge_attributes() else None).as_clustering()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15bf0ab-7b54-4f89-b6f6-e49ae9de6c54",
   "metadata": {},
   "source": [
    "# Functions useful to test community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab35a72-4bcd-4391-8f28-85b39c6a29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_modularity_on_clustering(graph: ig.Graph, community_detection_method: str = \"multilevel\"):\n",
    "    partition = community_detection(graph, community_detection_method, weight_attribute_name=None)\n",
    "    return partition.modularity\n",
    "\n",
    "def rewire(graph: ig.Graph):\n",
    "    num_randomizations = 500  # Number of randomized networks to generate\n",
    "    modularity_random_networks = []\n",
    "    \n",
    "    \n",
    "    # TODO: Why is there a * 10 edge swaps\n",
    "    num_swaps_for_randomization = graph.ecount() * 10\n",
    "    \n",
    "    for i in range(num_randomizations):\n",
    "        # G.rewire() modifies the graph in-place, so we must work on a copy.\n",
    "        graph_random = graph.copy()\n",
    "    \n",
    "        graph_random.rewire(n=num_swaps_for_randomization)\n",
    "    \n",
    "        modularity_random_networks.append(get_modularity_on_clustering(graph_random))\n",
    "\n",
    "    return modularity_random_networks\n",
    "\n",
    "def plot_histogram(modularity_original: float, modularity_random_networks: list[float], graph_name: str=\"Karate Club Network\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(modularity_random_networks, bins=30, alpha=0.7, color='lightgreen',\n",
    "             edgecolor='black', label='Modularity of Randomized Networks')\n",
    "    \n",
    "    # Plot a vertical line for the original network's modularity\n",
    "    plt.axvline(modularity_original, color='red', linestyle='dashed', linewidth=2,\n",
    "                label=f'Original Network Modularity ({modularity_original:.4f})')\n",
    "    \n",
    "    plt.title(f'Modularity of Original vs. Randomized {graph_name} (igraph)')\n",
    "    plt.xlabel('Modularity Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_community_structure(graph: ig.Graph, graph_name: str = \"Karate Club Network\", community_detection_method: str = \"multilevel\"):\n",
    "    modularity_orig = get_modularity_on_clustering(graph, community_detection_method)\n",
    "    modularity_random_networks = rewire(graph)\n",
    "    plot_histogram(modularity_orig, modularity_random_networks, graph_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6168e-c9d8-4200-a7ef-fac6927408d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to run a target function with a timeout using multiprocessing\n",
    "def _run_with_timeout(func, args=(), kwargs={}, timeout_seconds=60):\n",
    "    \"\"\"\n",
    "    Runs a function in a separate process with a timeout.\n",
    "    Returns (result, True) if successful, (None, False) if timeout occurs.\n",
    "    \"\"\"\n",
    "    # Use a multiprocessing.Queue to get the result from the child process\n",
    "    q = multiprocessing.Queue()\n",
    "    \n",
    "    def target():\n",
    "        try:\n",
    "            res = func(*args, **kwargs)\n",
    "            q.put((res, None)) # Put result and no exception\n",
    "        except Exception as e:\n",
    "            q.put((None, e)) # Put no result and the exception\n",
    "\n",
    "    process = multiprocessing.Process(target=target)\n",
    "    process.start()\n",
    "    process.join(timeout=timeout_seconds)\n",
    "\n",
    "    if process.is_alive():\n",
    "        # If the process is still alive, it means it timed out\n",
    "        print(f\"Warning: Function '{func.__name__}' timed out after {timeout_seconds} seconds. Terminating process.\")\n",
    "        process.terminate() # Forcefully terminate the process\n",
    "        process.join() # Wait for termination\n",
    "        time.sleep(0.01) # Small delay to allow OS cleanup after termination attempt\n",
    "        return None, False, None # Return None result, False for success, None for exception\n",
    "    else:\n",
    "        # Process finished, check for result or exception\n",
    "        if not q.empty():\n",
    "            res, exception = q.get()\n",
    "            if exception:\n",
    "                raise exception # Re-raise any exception caught in the process\n",
    "            return res, True, None # Return result, True for success\n",
    "        else:\n",
    "            # This case might happen if process terminates unexpectedly without putting anything\n",
    "            print(f\"Warning: Process for '{func.__name__}' finished but no result was put in queue.\")\n",
    "            return None, False, None\n",
    "\n",
    "\n",
    "def generate_reference_partition(graph: ig.Graph, optimal_timeout_seconds: int, use_optimal_as_reference: bool = True):\n",
    "    reference_partition = None\n",
    "    if use_optimal_as_reference:\n",
    "        ref_partition_result, success, exception = _run_with_timeout(\n",
    "            graph.community_optimal_modularity,\n",
    "            timeout_seconds=optimal_timeout_seconds\n",
    "        )\n",
    "        if success and ref_partition_result is not None:\n",
    "            reference_partition = ref_partition_result\n",
    "            print(f\"Optimal partition found with modularity: {reference_partition.modularity:.4f}\")\n",
    "        else:\n",
    "            if exception:\n",
    "                print(f\"Optimal partition calculation failed with error: {exception}\")\n",
    "            print(\"Falling back to a fixed-seed Louvain partition as reference.\")\n",
    "            # Fallback for larger graphs or if optimal fails/times out\n",
    "            random.seed(42) # Fix seed for a reproducible reference\n",
    "            reference_partition = graph.community_multilevel()\n",
    "            random.seed(None) # Unset seed for subsequent stochastic runs\n",
    "            print(f\"Reference Louvain partition (fixed seed) found with modularity: {reference_partition.modularity:.4f}\")\n",
    "    else:\n",
    "        # Option B: Louvain with fixed seed as reference (for larger graphs)\n",
    "        print(\"\\nUsing a fixed-seed Louvain partition as reference.\")\n",
    "        random.seed(42) # Fix seed for a reproducible reference\n",
    "        reference_partition = graph.community_multilevel()\n",
    "        random.seed(None) # Unset seed for subsequent stochastic runs\n",
    "        print(f\"Reference Louvain partition (fixed seed) found with modularity: {reference_partition.modularity:.4f}\")\n",
    "\n",
    "    \n",
    "    if reference_partition is None:\n",
    "        raise(\"Could not establish a reference partition\")\n",
    "\n",
    "    return reference_partition\n",
    "\n",
    "def run_stochastic_community_detection(graph, reference_partition: ig.clustering.VertexClustering, num_runs: int, community_detection_method: str = \"multilevel\"):\n",
    "    nmi_values = []\n",
    "    print(f\"\\nRunning Louvain community detection {num_runs} times and calculating NMI...\")\n",
    "\n",
    "    if community_detection_method == \"multilevel\":\n",
    "        community_detection = graph.community_multilevel\n",
    "        params = None\n",
    "    elif community_detection_method == \"leiden\":\n",
    "        community_detection = graph.community_leiden\n",
    "        params = {\n",
    "            \"objective_function\": \"modularity\", \n",
    "            \"resolution_parameter\": 1.0\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Invalid community_detection_method. Choose 'multilevel' or 'leiden'.\")\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        random.seed()\n",
    "        if params is not None:\n",
    "            current_partition = community_detection(**params)\n",
    "        else:\n",
    "            current_partition = community_detection()\n",
    "        \n",
    "        # Calculate NMI between the current partition and the reference partition\n",
    "        # 'method='nmi'' specifies Normalized Mutual Information\n",
    "        nmi = ig.compare_communities(reference_partition, current_partition, method='nmi')\n",
    "        nmi_values.append(nmi)\n",
    "\n",
    "        if (i + 1) % (num_runs // 10 if num_runs >= 10 else 1) == 0:\n",
    "            print(f\"  Processed {i + 1}/{num_runs} runs.\")\n",
    "    print(nmi_values)\n",
    "    return nmi_values\n",
    "\n",
    "def plot_nmi_histogram(graph, nmi_values):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(nmi_values, bins=60, edgecolor='black', alpha=0.7, color='lightcoral')\n",
    "    plt.title(f'Histogram of NMI Values (Louvain vs. Reference Partition) for {graph.vcount()} nodes')\n",
    "    plt.xlabel('Normalized Mutual Information (NMI) Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "    # Add a line for the mean NMI\n",
    "    mean_nmi = np.mean(nmi_values)\n",
    "    plt.axvline(mean_nmi, color='blue', linestyle='dashed', linewidth=2,\n",
    "                label=f'Mean NMI: {mean_nmi:.4f}')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e018281-2fe7-4c7c-b608-c2e97e315e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf852df-81bd-41c5-9175-f4d7b184ac4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
